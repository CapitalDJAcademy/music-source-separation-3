{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import librosa, librosa.display\n",
    "\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('..','..','data')\n",
    "\n",
    "\n",
    "config = {\n",
    "    \"batch_size\": 8\n",
    "}\n",
    "\n",
    "std = 0.22\n",
    "mean = 0.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(filename, sample_duration):\n",
    "    df = pd.read_csv(filename, sep='\\t').dropna()\n",
    "    files = '../../data/multitracks/' + df['song'] + '/' + df['track']\n",
    "    labels = df['label']\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensors((files.values, tf.cast(labels.values, tf.int32))).unbatch()\n",
    "    dataset = dataset.map(lambda filename, label: (tfio.IOTensor.graph(tf.int16).from_audio(filename).to_tensor(), label))\n",
    "    dataset = dataset.map(lambda wav, label: (wav, label, tf.shape(wav)[0] / 44100))\n",
    "    dataset = dataset.map(lambda wav, label, duration: (create_feature(wav, duration, sample_duration), create_label(label, duration, sample_duration)), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset.unbatch().filter(has_signal).prefetch(32)\n",
    "\n",
    "@tf.function\n",
    "def create_feature(wav, duration, sample_duration):\n",
    "    wav = tf.cast(wav, tf.float32) / 32767\n",
    "    #wav = tf.math.reduce_mean(wav, axis=1)  # make mono\n",
    "    mono = tf.math.reduce_mean(wav, axis=1)  # make mono\n",
    "    # spectrogram (100 steps/sec with 1025 channels)\n",
    "    fft = tf.signal.stft(mono, 2048, 441, pad_end=True)\n",
    "    fft = tf.abs(fft)\n",
    "    spec = tf.math.log1p(fft)# * fft\n",
    "    \n",
    "    spec = scale(spec, std, mean)\n",
    "\n",
    "    # split into timesteps (10ms * chunk_size)\n",
    "    spec = tf.reshape(spec, [-1, 100 * sample_duration, 1025])\n",
    "    return spec\n",
    "\n",
    "@tf.function\n",
    "def create_label(y, duration, sample_duration):\n",
    "    y = tf.one_hot(y,3)\n",
    "    y = tf.reshape(y, [-1, 3])\n",
    "    return tf.repeat(y, int(duration / sample_duration), 0)\n",
    "\n",
    "@tf.function\n",
    "def has_signal(wav, label):\n",
    "    return tf.math.reduce_max(tf.abs(wav)) > 0.1\n",
    "\n",
    "@tf.function\n",
    "def scale(x, std, mean):\n",
    "    return (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_15 (GRU)                 (None, 1)                 3084      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 3)                 6         \n",
      "=================================================================\n",
      "Total params: 3,090\n",
      "Trainable params: 3,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(1, return_sequences=False, input_shape=(None, 1025)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy','binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24307898\n",
      "0.2526298\n",
      "0.09056211\n",
      "0.13342454\n",
      "0.1626367\n",
      "0.09940865\n",
      "0.24771799\n",
      "0.3643004\n",
      "0.29029447\n",
      "0.05667586\n",
      "0.024456015\n",
      "0.19681206\n",
      "0.17358142\n",
      "0.24179499\n",
      "0.21352437\n",
      "0.12536286\n",
      "0.18132336\n",
      "0.20680566\n",
      "0.23869698\n",
      "0.27562138\n",
      "0.2166498\n",
      "0.20339516\n",
      "0.26985937\n",
      "0.25677386\n",
      "0.19807649\n",
      "0.15130658\n",
      "0.24211769\n",
      "0.295714\n",
      "0.32899982\n",
      "0.08144931\n",
      "0.10811776\n",
      "0.27780747\n",
      "0.27776062\n",
      "0.32640076\n",
      "0.22089773\n",
      "0.15547466\n",
      "0.2740978\n",
      "0.12892884\n",
      "0.2587987\n",
      "0.27342868\n",
      "0.33881405\n",
      "0.34255624\n",
      "0.30078632\n",
      "0.002476396\n",
      "0.22392088\n",
      "0.25881702\n",
      "0.3203019\n",
      "0.28831795\n",
      "0.27265388\n",
      "0.34180203\n"
     ]
    }
   ],
   "source": [
    "train = create_dataset(os.path.join(data_path,'classification_al','train.csv'),10).take(50)\n",
    "for x,y in train.as_numpy_iterator():\n",
    "    #vals = x.reshape(-1)\n",
    "    print(np.std(x))\n",
    "    #plt.figure()\n",
    "    #plt.hist(vals, bins=10, range=(0,0.1))\n",
    "    #plt.show()\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Runs\n",
    "3 Run:\n",
    "- without any normalization (`spec = fft^2`)\n",
    "- use `log(fft)`\n",
    "- standardize & `log(fft)`\n",
    "\n",
    "as filter (remove silence) is applied afterwards samples might differ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19223/19223 [==============================] - 1753s 91ms/step - loss: 1.4411 - accuracy: 0.8549 - binary_accuracy: 0.9013 - val_loss: 3.0196 - val_accuracy: 0.6323 - val_binary_accuracy: 0.7549\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6c2c3e9fd0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = create_dataset(os.path.join(data_path,'classification_al','train.csv'),1).batch(config[\"batch_size\"])\n",
    "dev = create_dataset(os.path.join(data_path,'classification_al','dev.csv'),1).batch(config[\"batch_size\"])\n",
    "model.fit(train, validation_data=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20363/20363 [==============================] - 2064s 101ms/step - loss: 0.8933 - accuracy: 0.8627 - binary_accuracy: 0.9103 - val_loss: 2.0885 - val_accuracy: 0.6354 - val_binary_accuracy: 0.7569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6c2c482f50>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = create_dataset(os.path.join(data_path,'classification_al','train.csv'),1).batch(config[\"batch_size\"])\n",
    "dev = create_dataset(os.path.join(data_path,'classification_al','dev.csv'),1).batch(config[\"batch_size\"])\n",
    "model.fit(train, validation_data=dev)function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30107/30107 [==============================] - 2422s 80ms/step - loss: 0.6617 - accuracy: 0.8431 - binary_accuracy: 0.8957 - val_loss: 5.4978 - val_accuracy: 0.5770 - val_binary_accuracy: 0.7224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6c05e1d4d0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = create_dataset(os.path.join(data_path,'classification_al','train.csv'),1).batch(config[\"batch_size\"])\n",
    "dev = create_dataset(os.path.join(data_path,'classification_al','dev.csv'),1).batch(config[\"batch_size\"])\n",
    "model.fit(train, validation_data=dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
